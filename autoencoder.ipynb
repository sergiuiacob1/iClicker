{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "from math import exp, sqrt, pi, floor\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gaussian(\n",
    "        size=3, sigma=0.25, amplitude=1, normalize=False, width=None,\n",
    "        height=None, sigma_horz=None, sigma_vert=None, mean_horz=0.5,\n",
    "        mean_vert=0.5):\n",
    "    # handle some defaults\n",
    "    if width is None:\n",
    "        width = size\n",
    "    if height is None:\n",
    "        height = size\n",
    "    if sigma_horz is None:\n",
    "        sigma_horz = sigma\n",
    "    if sigma_vert is None:\n",
    "        sigma_vert = sigma\n",
    "    center_x = mean_horz * width + 0.5\n",
    "    center_y = mean_vert * height + 0.5\n",
    "    gauss = np.empty((height, width), dtype=np.float32)\n",
    "    # generate kernel\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            gauss[i][j] = amplitude * math.exp(-(math.pow((j + 1 - center_x) / (\n",
    "                sigma_horz * width), 2) / 2.0 + math.pow((i + 1 - center_y) / (sigma_vert * height), 2) / 2.0))\n",
    "    if normalize:\n",
    "        gauss = gauss / np.sum(gauss)\n",
    "    return gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hm_from_lm(image, point, sigma):\n",
    "        ul = [math.floor(point[0] - 3 * sigma), math.floor(point[1] - 3 * sigma)]\n",
    "        br = [math.floor(point[0] + 3 * sigma), math.floor(point[1] + 3 * sigma)]\n",
    "        if (ul[0] > image.shape[1] or ul[1] >\n",
    "                image.shape[0] or br[0] < 1 or br[1] < 1):\n",
    "            return image\n",
    "        size = 6 * sigma + 1\n",
    "        g = _gaussian(size)\n",
    "        g_x = [int(max(1, -ul[0])), int(min(br[0], image.shape[1])) -\n",
    "               int(max(1, ul[0])) + int(max(1, -ul[0]))]\n",
    "        g_y = [int(max(1, -ul[1])), int(min(br[1], image.shape[0])) -\n",
    "               int(max(1, ul[1])) + int(max(1, -ul[1]))]\n",
    "        img_x = [int(max(1, ul[0])), int(min(br[0], image.shape[1]))]\n",
    "        img_y = [int(max(1, ul[1])), int(min(br[1], image.shape[0]))]\n",
    "        assert (g_x[0] > 0 and g_y[1] > 0)\n",
    "        image[img_y[0] - 1:img_y[1], img_x[0] - 1:img_x[1]\n",
    "              ] = image[img_y[0] - 1:img_y[1], img_x[0] - 1:img_x[1]] + g[g_y[0] - 1:g_y[1], g_x[0] - 1:g_x[1]]\n",
    "        image[image > 1] = 1\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_center_and_radius(img_name):\n",
    "    eye_centers = {}\n",
    "    with open('crowdpupil/results.csv', newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=';')\n",
    "        for row in spamreader:\n",
    "            eye_centers[row[0]] = (int(row[1]), int(row[2]))\n",
    "            \n",
    "    with open('crowdpupil/eye_radius.json', 'r') as fp:\n",
    "        eye_radius = json.load(fp)\n",
    "            \n",
    "    return (eye_centers[img_name], sum(eye_radius.values())/len(eye_radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_images = os.listdir('./crowdpupil/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = random.choice(eye_images)\n",
    "img = cv2.imread('./crowdpupil/images/' + img_name)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_from_img (img_name):\n",
    "    img = cv2.imread('crowdpupil/images/' + img_name)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    center, radius = get_img_center_and_radius(img_name)\n",
    "\n",
    "    m1 = center\n",
    "    s1 = np.eye(2) * radius ** 1.5\n",
    "    k1 = multivariate_normal(mean=m1, cov=s1)\n",
    "\n",
    "    # create a grid of (x,y) coordinates at which to evaluate the kernels\n",
    "    x = np.linspace(0, img.shape[1], img.shape[1])\n",
    "    y = np.linspace(0, img.shape[0], img.shape[0])\n",
    "    xx, yy = np.meshgrid(x,y)\n",
    "\n",
    "    # evaluate kernels at grid points\n",
    "    xxyy = np.c_[xx.ravel(), yy.ravel()]\n",
    "    zz = k1.pdf(xxyy)\n",
    "\n",
    "    # reshape and plot image\n",
    "    heatmap = zz.reshape(img.shape)\n",
    "    a = heatmap * 255 / np.amax(heatmap)\n",
    "    cv2.imwrite('crowdpupil/heatmaps/h_' + img_name, heatmap * 255 / np.amax(heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('crowdpupil/heatmaps', exist_ok=True)\n",
    "for index, img in enumerate(eye_images):\n",
    "    generate_heatmap_from_img(img)\n",
    "    if index % 50 == 0:\n",
    "        print (f'Done {index}/{len(eye_images)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use AutoEncoder with the heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "# load all of the heatmaps\n",
    "h_list = os.listdir('./crowdpupil/heatmaps')\n",
    "all_data = []\n",
    "for index, h in enumerate(h_list):\n",
    "    if index % 100 == 0:\n",
    "        print (f'Done {index}/{len(all_data)}')\n",
    "    img = cv2.imread('./crowdpupil/heatmaps/' + h, cv2.IMREAD_GRAYSCALE)\n",
    "    # resize the image to a fixed dimension\n",
    "    img = cv2.resize(img, (1000//2, 776//2), interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(1, 776//2, 1000//2)\n",
    "    img = img/255\n",
    "    img = torch.from_numpy(img).float()\n",
    "    all_data.append(img)\n",
    "    \n",
    "print (len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test\n",
    "random.shuffle(all_data)\n",
    "split_size = 0.8\n",
    "train_size = int(len(all_data) * split_size)\n",
    "train_data = all_data[:train_size]\n",
    "test_data = all_data[train_size:]\n",
    "\n",
    "print (len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 32\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(random.choice(images))\n",
    "\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        ## encoder layers ##\n",
    "        # conv layer (depth from 1 --> 16), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  \n",
    "        # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## encode ##\n",
    "        # add hidden layers with relu activation function\n",
    "        # and maxpooling after\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # compressed representation\n",
    "        \n",
    "        ## decode ##\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        # _ stands in for labels, here\n",
    "        # no need to flatten images\n",
    "        images = data\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, images)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Training time: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss,\n",
    "        time.time() - start_time\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(batch_size, 1, 776//2, 1000//2)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to generate heatmap from eye image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps:\n",
    "# 1. get data: that's eye images + corresponding heatmaps\n",
    "# 2. build CNN architecture (inspire yourself from CCNN)\n",
    "# 3. train. see results.\n",
    "# 4. extract landmark from heatmap\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get data: eye images + corresponding heatmaps\n",
    "eye_images = os.listdir('./crowdpupil/images')\n",
    "eye_images.sort()\n",
    "heatmaps = os.listdir('./crowdpupil/heatmaps')\n",
    "heatmaps.sort()\n",
    "\n",
    "img_width = 256\n",
    "img_height = 200\n",
    "# img_width = 1000//4\n",
    "# img_height = 776//4\n",
    "\n",
    "# load images\n",
    "for index, f in enumerate(eye_images):\n",
    "    img = cv2.imread('./crowdpupil/images/' + f)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(1, img_height, img_width)\n",
    "    img = img/255\n",
    "    img = torch.from_numpy(img).float()\n",
    "    eye_images[index] = img\n",
    "\n",
    "# load heatmaps\n",
    "for index, f in enumerate(heatmaps):\n",
    "    img = cv2.imread('./crowdpupil/heatmaps/' + f, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(1, img_height, img_width)\n",
    "    img = img/255\n",
    "    img = torch.from_numpy(img).float()\n",
    "    heatmaps[index] = img\n",
    "    \n",
    "# split train/test\n",
    "split_size = 0.8\n",
    "train_size = int(len(eye_images) * split_size)\n",
    "train_data = list(zip(eye_images[:train_size], heatmaps[:train_size]))\n",
    "test_data = list(zip(eye_images[train_size:], heatmaps[train_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x157c90390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "choice = random.randint(0, len(eye_images))\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(eye_images[choice].squeeze(), cmap='gray')\n",
    "axarr[1].imshow(heatmaps[choice].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Build the CNN architecture. Input: eye image. Output: heatmap.\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        ## shared layers\n",
    "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        self.pool_2_2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        ## first part: from image -> feature maps\n",
    "        self.conv1_1 = nn.Conv2d(1, 128, 3, padding=2)\n",
    "        self.conv1_2 = nn.Conv2d(128, 64, 3, padding=2)\n",
    "        self.conv1_3 = nn.Conv2d(64, 32, 3, padding=2)\n",
    "        \n",
    "        ## second part: from feature maps -> heatmap\n",
    "        self.conv2_1 = nn.Conv2d(32, 16, 2, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(16, 4, 3, padding=2)\n",
    "        self.dropout2_1 = nn.Dropout(p=0.5)\n",
    "        self.conv2_3 = nn.Conv2d(4, 1, 3, padding=2)\n",
    "        # now construct the heatmap to have the same shape as the input image\n",
    "        self.t_conv2_1 = nn.ConvTranspose2d(1, 4, 3, padding=2)\n",
    "        self.t_conv2_2 = nn.ConvTranspose2d(4, 16, 3, padding=2)\n",
    "        self.t_conv2_3 = nn.ConvTranspose2d(16, 32, 2, padding=1)\n",
    "        self.t_conv2_4 = nn.ConvTranspose2d(32, 1, 3, padding=4)\n",
    "\n",
    "        \n",
    "        ## third part: from heatmap -> heatmap\n",
    "        # conv layer (depth from 1 --> 16), 3x3 kernels\n",
    "        self.conv3_1 = nn.Conv2d(1, 16, 3, padding=1)  \n",
    "        # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "        self.conv3_2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## first part: image -> feature maps\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.relu(self.conv1_3(x))\n",
    "#         x = self.pool_2_2(x)\n",
    "#         print (x.shape)\n",
    "        \n",
    "        ## second part: feature maps -> heatmap\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.dropout2_1(x)\n",
    "        x = F.relu(self.conv2_3(x))\n",
    "        \n",
    "        # apply transpose convolution, to make the heatmap have the same shape as the input image\n",
    "        x = F.relu(self.t_conv2_1(x))\n",
    "        x = F.relu(self.t_conv2_2(x))\n",
    "        x = F.relu(self.t_conv2_3(x))\n",
    "        x = F.relu(self.t_conv2_4(x))\n",
    "        \n",
    "        ## third part: autoencoder\n",
    "        ## encode ##\n",
    "        # add hidden layers with relu activation function\n",
    "        # and maxpooling after\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = self.pool_2_2(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = self.pool_2_2(x)  # compressed representation\n",
    "        \n",
    "        ## decode ##\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 32\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch 1 item loss: 6.610284328460693\n",
      "epoch 1 batch 2 item loss: 0.19020375609397888\n",
      "epoch 1 batch 3 item loss: 0.15308715403079987\n",
      "epoch 1 batch 4 item loss: 0.153787299990654\n",
      "epoch 1 batch 5 item loss: 0.1516958475112915\n",
      "epoch 1 batch 6 item loss: 0.15133371949195862\n",
      "epoch 1 batch 7 item loss: 0.15168732404708862\n",
      "epoch 1 batch 8 item loss: 0.15414142608642578\n",
      "epoch 1 batch 9 item loss: 0.15309390425682068\n",
      "epoch 1 batch 10 item loss: 0.15204370021820068\n",
      "epoch 1 batch 11 item loss: 0.15379533171653748\n",
      "epoch 1 batch 12 item loss: 0.15098877251148224\n",
      "epoch 1 batch 13 item loss: 0.15169189870357513\n",
      "epoch 1 batch 14 item loss: 0.1544876992702484\n",
      "epoch 1 batch 15 item loss: 0.15203553438186646\n",
      "epoch 1 batch 16 item loss: 0.15168720483779907\n",
      "epoch 1 batch 17 item loss: 0.15273720026016235\n",
      "epoch 1 batch 18 item loss: 0.15274661779403687\n",
      "epoch 1 batch 19 item loss: 0.15344475209712982\n",
      "epoch 1 batch 20 item loss: 0.11931409826502204\n",
      "0.0025000000000000005\n",
      "Epoch: 1 \tTraining Loss: 0.475714 \t Training time: 586.416271\n",
      "epoch 2 batch 1 item loss: 0.1516798585653305\n",
      "epoch 2 batch 2 item loss: 0.1534443348646164\n",
      "epoch 2 batch 3 item loss: 0.15133140981197357\n",
      "epoch 2 batch 4 item loss: 0.15309804677963257\n",
      "epoch 2 batch 5 item loss: 0.15168696641921997\n",
      "epoch 2 batch 6 item loss: 0.1530931442975998\n",
      "epoch 2 batch 7 item loss: 0.15343324840068817\n",
      "epoch 2 batch 8 item loss: 0.15238399803638458\n",
      "epoch 2 batch 9 item loss: 0.15414471924304962\n",
      "epoch 2 batch 10 item loss: 0.14993669092655182\n",
      "epoch 2 batch 11 item loss: 0.15274155139923096\n",
      "epoch 2 batch 12 item loss: 0.1523984968662262\n",
      "epoch 2 batch 13 item loss: 0.15449756383895874\n",
      "epoch 2 batch 14 item loss: 0.1534382402896881\n",
      "epoch 2 batch 15 item loss: 0.1534399837255478\n",
      "epoch 2 batch 16 item loss: 0.15204304456710815\n",
      "epoch 2 batch 17 item loss: 0.15308672189712524\n",
      "epoch 2 batch 18 item loss: 0.1509842872619629\n",
      "epoch 2 batch 19 item loss: 0.1520444005727768\n",
      "epoch 2 batch 20 item loss: 0.11931759072467685\n",
      "0.00025000000000000006\n",
      "Epoch: 2 \tTraining Loss: 0.150911 \t Training time: 607.240266\n",
      "epoch 3 batch 1 item loss: 0.1523907482624054\n",
      "epoch 3 batch 2 item loss: 0.15274381637573242\n",
      "epoch 3 batch 3 item loss: 0.1541440337896347\n",
      "epoch 3 batch 4 item loss: 0.15239062905311584\n",
      "epoch 3 batch 5 item loss: 0.15238803625106812\n",
      "epoch 3 batch 6 item loss: 0.15274304151535034\n",
      "epoch 3 batch 7 item loss: 0.15204113721847534\n",
      "epoch 3 batch 8 item loss: 0.15344122052192688\n",
      "epoch 3 batch 9 item loss: 0.15272976458072662\n",
      "epoch 3 batch 10 item loss: 0.1513330489397049\n",
      "epoch 3 batch 11 item loss: 0.15379327535629272\n",
      "epoch 3 batch 12 item loss: 0.1537952721118927\n",
      "epoch 3 batch 13 item loss: 0.15169237554073334\n",
      "epoch 3 batch 14 item loss: 0.15238633751869202\n",
      "epoch 3 batch 15 item loss: 0.15203191339969635\n",
      "epoch 3 batch 16 item loss: 0.1523781716823578\n",
      "epoch 3 batch 17 item loss: 0.15309767425060272\n",
      "epoch 3 batch 18 item loss: 0.15379272401332855\n",
      "epoch 3 batch 19 item loss: 0.1509922444820404\n",
      "epoch 3 batch 20 item loss: 0.11791958240792155\n",
      "2.5000000000000008e-05\n",
      "Epoch: 3 \tTraining Loss: 0.150911 \t Training time: 597.442378\n",
      "epoch 4 batch 1 item loss: 0.15239104628562927\n",
      "epoch 4 batch 2 item loss: 0.15413762629032135\n",
      "epoch 4 batch 3 item loss: 0.152391254901886\n",
      "epoch 4 batch 4 item loss: 0.15273417532444\n",
      "epoch 4 batch 5 item loss: 0.15204115211963654\n",
      "epoch 4 batch 6 item loss: 0.151345893740654\n",
      "epoch 4 batch 7 item loss: 0.15379232168197632\n",
      "epoch 4 batch 8 item loss: 0.1516832709312439\n",
      "epoch 4 batch 9 item loss: 0.15238747000694275\n",
      "epoch 4 batch 10 item loss: 0.15239496529102325\n",
      "epoch 4 batch 11 item loss: 0.15448732674121857\n",
      "epoch 4 batch 12 item loss: 0.1534382402896881\n",
      "epoch 4 batch 13 item loss: 0.15308794379234314\n",
      "epoch 4 batch 14 item loss: 0.15168210864067078\n",
      "epoch 4 batch 15 item loss: 0.15203934907913208\n",
      "epoch 4 batch 16 item loss: 0.15238478779792786\n",
      "epoch 4 batch 17 item loss: 0.15343600511550903\n",
      "epoch 4 batch 18 item loss: 0.15169207751750946\n",
      "epoch 4 batch 19 item loss: 0.15205563604831696\n",
      "epoch 4 batch 20 item loss: 0.11862162500619888\n",
      "2.5000000000000008e-05\n",
      "Epoch: 4 \tTraining Loss: 0.150911 \t Training time: 573.172284\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model = MyCNN()\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.025)\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[1, 2, 3, 5, 7, 10], gamma = 0.1)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 4\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        # no need to flatten images\n",
    "        images, heatmaps = data\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, heatmaps)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        print (f'epoch {epoch} batch {i} item loss: {loss.item() * images.size(0)}')\n",
    "            \n",
    "    my_lr_scheduler.step()\n",
    "    \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Training time: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss,\n",
    "        time.time() - start_time\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the model's result\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, heatmaps = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(batch_size, 1, img_height, img_width)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model predictions\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([heatmaps, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
